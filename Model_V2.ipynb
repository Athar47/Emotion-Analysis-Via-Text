{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOnFSduknJKHYkKPiI1uVPQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Athar47/Emotion-Analysis-Via-Text/blob/main/Model_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRNjq0uyXoob",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import nltk\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download(\"stopwords\")\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read datasets\n",
        "df_train = pd.read_csv('train.txt', names=['Text', 'Emotion'], sep=';')\n",
        "df_val = pd.read_csv('val.txt', names=['Text', 'Emotion'], sep=';')\n",
        "df_test = pd.read_csv('test.txt', names=['Text', 'Emotion'], sep=';')"
      ],
      "metadata": {
        "id": "o_GNurbYYGsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing duplicated values in df_train\n",
        "df_train = df_train.drop_duplicates().reset_index(drop=True)\n",
        "\n",
        "# Removing duplicated text in df_val\n",
        "df_val = df_val.drop_duplicates(subset=['Text']).reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "ZV6wGnGZYHIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lemmatization(text):\n",
        "    # Lemmatize each word in the text\n",
        "    lemmatized_text = [lemmatizer.lemmatize(word) for word in text.split()]\n",
        "    return \" \".join(lemmatized_text)\n",
        "\n",
        "def remove_stop_words(text):\n",
        "    # Remove stop words from the text\n",
        "    filtered_text = [word for word in str(text).split() if word not in stop_words]\n",
        "    return \" \".join(filtered_text)\n",
        "\n",
        "def removing_numbers(text):\n",
        "    # Remove digits from the text\n",
        "    return ''.join([char for char in text if not char.isdigit()])\n",
        "\n",
        "def lower_case(text):\n",
        "    # Convert text to lowercase\n",
        "    return \" \".join([word.lower() for word in text.split()])\n",
        "\n",
        "def removing_punctuations(text):\n",
        "    # Remove punctuations, extra whitespace, and specific characters\n",
        "    text = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,،-./:;<=>؟?@[\\]^_`{|}~\"\"\"), ' ', text)\n",
        "    text = text.replace('؛', \"\")\n",
        "    text = re.sub('\\s+', ' ', text)\n",
        "    return text.strip()\n",
        "\n",
        "def removing_urls(text):\n",
        "    # Remove URLs from the text\n",
        "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    return url_pattern.sub(r'', text)\n",
        "\n",
        "def remove_small_sentences(df):\n",
        "    # Remove rows with small sentences (less than 3 words)\n",
        "    df['Text'] = df['Text'].apply(lambda text: np.nan if len(str(text).split()) < 3 else text)\n",
        "\n",
        "def normalize_text(df):\n",
        "    # Apply various text normalization functions to the 'Text' column\n",
        "    df['Text'] = df['Text'].apply(lower_case)\n",
        "    df['Text'] = df['Text'].apply(remove_stop_words)\n",
        "    df['Text'] = df['Text'].apply(removing_numbers)\n",
        "    df['Text'] = df['Text'].apply(removing_punctuations)\n",
        "    df['Text'] = df['Text'].apply(removing_urls)\n",
        "    df['Text'] = df['Text'].apply(lemmatization)\n",
        "    return df\n",
        "\n",
        "def normalized_sentence(sentence):\n",
        "    # Apply various text normalization functions to a single sentence\n",
        "    sentence = lower_case(sentence)\n",
        "    sentence = remove_stop_words(sentence)\n",
        "    sentence = removing_numbers(sentence)\n",
        "    sentence = removing_punctuations(sentence)\n",
        "    sentence = removing_urls(sentence)\n",
        "    sentence = lemmatization(sentence)\n",
        "    return sentence\n"
      ],
      "metadata": {
        "id": "kFxmgaXtYUgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the text for training, testing, and validation datasets\n",
        "df_train = normalize_text(df_train)\n",
        "df_test = normalize_text(df_test)\n",
        "df_val = normalize_text(df_val)"
      ],
      "metadata": {
        "id": "NNDFHDFdYXPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract features and labels for training data\n",
        "X_train = df_train['Text'].values\n",
        "y_train = df_train['Emotion'].values\n",
        "\n",
        "# Extract features and labels for test data\n",
        "X_test = df_test['Text'].values\n",
        "y_test = df_test['Emotion'].values\n",
        "\n",
        "# Extract features and labels for validation data\n",
        "X_val = df_val['Text'].values\n",
        "y_val = df_val['Emotion'].values"
      ],
      "metadata": {
        "id": "lyn4zCDPYYZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, data, targets):\n",
        "    # Create a Pipeline with TfidfVectorizer and the given model\n",
        "    text_clf = Pipeline([('vect', TfidfVectorizer()),\n",
        "                         ('clf', model)])\n",
        "    # Fit the model on the data and targets\n",
        "    text_clf.fit(data, targets)\n",
        "    return text_clf"
      ],
      "metadata": {
        "id": "fbYijdyjYZhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model with the training data\n",
        "RF = train_model(RandomForestClassifier(random_state=0), X_train, y_train)\n",
        "\n",
        "# Test the model with the test data\n",
        "y_pred = RF.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy\n",
        "RF_accuracy = accuracy_score(y_test, y_pred)\n",
        "print('Accuracy: ', RF_accuracy, '\\n')"
      ],
      "metadata": {
        "id": "524T4f4QYgAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Classification Report\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "5d09OlE5YhDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# User input prediction\n",
        "user_input = input(\"Enter a text (at least 5 words): \")\n",
        "while len(user_input.split()) < 5:\n",
        "    print(\"Please enter at least 5 words.\")\n",
        "    user_input = input(\"Enter a text (at least 5 words): \")\n",
        "\n",
        "# Normalize the user input\n",
        "normalized_input = normalize_text(pd.DataFrame({'Text': [user_input]})).iloc[0]['Text']\n",
        "\n",
        "# Make prediction using the trained RandomForestClassifier model\n",
        "user_pred = RF.predict([normalized_input])\n",
        "\n",
        "# Print the predicted emotion\n",
        "print(\"Predicted Emotion:\", user_pred[0])"
      ],
      "metadata": {
        "id": "d-DOaCH4YiLL",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M-fM4LCCYjOD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}